{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f858e305",
   "metadata": {},
   "source": [
    "# HW11: 歌曲种类分类\n",
    "\n",
    "如果有问题请在群里讨论，题意问题请@姜腾\n",
    "\n",
    "ddl周六（4.16）23:59，提交前请自己重启kernel运行一遍，只提交ipynb文件，不要把数据打包"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba53662",
   "metadata": {},
   "source": [
    "由于大家期中临近，所以这次作业很大一部分已经由助教给出。尤其是对英文语料预处理的部分，只是希望大家注意一下处理英文语料和中文语料的差别之处，比如需要Lemmatization（比如把过去式还原），还有去除停词。\n",
    "\n",
    "基本任务描述：\n",
    "本数据集是已经整理拼接好的数据集，包含了r&b, latin, rock, pop, rap, edm六个音乐种类的歌曲的歌词和音频特征。\n",
    "\n",
    "特征部分是用的Spotify的api提供的音频分析数据，已经由原音频文件特征工程得来（如果大家对音频分析感兴趣，可以去搜一下[librosa](http://librosa.org/doc/latest/index.html)包，是专业分析音频的包。12个音频特征如下: acousticness, danceability, durationms, energy, instrumentalness, key, liveness, loudness, mode, speechiness, tempo, valence.具体含义参考[链接](https://developer.spotify.com/web-api/get-audio-features/)，比如key的1和0就是大小调的区别。\n",
    "\n",
    "为了任务简单，本次只用rock, pop, rap三种的音乐，每种抽样1500首歌。预测目标是playlist_genre，即歌曲所属的歌单表征歌曲的种类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734a3969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可能用到的包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# 也有可能用到其他的方法，比如什么Complement Naive Bayes，如果你觉得有必要的话\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "random.seed(1)\n",
    "#nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331981f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据读入和预处理\n",
    "\n",
    "nRowsRead = None # specify 'None' if want to read whole file\n",
    "data = pd.read_csv('./spotify_songs.csv', delimiter=',', nrows = nRowsRead)\n",
    "\n",
    "# data preprocessing\n",
    "\n",
    "# step1: Removing Numbers, Punctuations and Lowercasing the Words¶\n",
    "\n",
    "def rid_of_specials(lyrics):\n",
    "    return re.sub('[^A-Za-z]+', ' ', lyrics).lower()\n",
    "data[\"lyrics\"] = data[\"lyrics\"].astype(str).apply(rid_of_specials)\n",
    "\n",
    "\n",
    "# step2: remove stopwords\n",
    "\n",
    "sw_nltk = (stopwords.words('english'))\n",
    "stop_words = set(sw_nltk)\n",
    "\n",
    "def remove_sw(x):\n",
    "    x = x.split(' ')\n",
    "    return  ' '.join(z for z in x if z not in stop_words)\n",
    "stopped = data[\"lyrics\"].apply(remove_sw)\n",
    "\n",
    "# step3: lemmatizing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(i) for i in stopped]\n",
    "prepeared_sentence = [''.join(j) for j in lemmatized]\n",
    "data['Lyrics_Processed'] = prepeared_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a227750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['track_id', 'track_name', 'track_artist', 'lyrics', 'track_popularity',\n",
       "       'track_album_id', 'track_album_name', 'track_album_release_date',\n",
       "       'playlist_name', 'playlist_id', 'playlist_genre', 'playlist_subgenre',\n",
       "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'duration_ms', 'language', 'Lyrics_Processed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138d4c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pop      3993\n",
       "rock     3521\n",
       "rap      3391\n",
       "r&b      3326\n",
       "latin    2178\n",
       "edm      2045\n",
       "Name: playlist_genre, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['playlist_genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1732109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['language']=='en'] # 只选出英文歌\n",
    "# 只留下pop，rock和rap\n",
    "data = data[data['playlist_genre']!='latin']\n",
    "data = data[data['playlist_genre']!='edm']\n",
    "data = data[data['playlist_genre']!='r&b']\n",
    "data = data.groupby('playlist_genre').sample(n=1500) #每种乐曲选出1500首"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1745c7",
   "metadata": {},
   "source": [
    "### 任务1: 只使用歌词\n",
    "\n",
    "歌词已经处理好了，任务为**只用歌词**实现朴素贝叶斯分类（注意一下使用哪种Naive Bayes）和Logistic回归分类。将歌词按照课上讲过的方法通过Count Vectorization或者TF-IDF Vectorization向量化作为特征输入训练模型，最后打印在测试集上的classification_report和confusion matrix。\n",
    "\n",
    "提示：强烈建议直接调包，会很简单的。可能用到的方法已经在最前面给出了。\n",
    "如果你遇到了TFIDF Vector能不能用于Multinomial Bayes的问题，这一篇blog或许可以解答你的疑惑。https://stackoverflow.com/questions/43237286/how-can-we-use-tfidf-vectors-with-multinomial-naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6415b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['Lyrics_Processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78bdc6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X.A,data['playlist_genre'],test_size=0.2,random_state=6)\n",
    "classifier = MultinomialNB().fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a909b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pop       0.59      0.71      0.65       296\n",
      "        rock       0.78      0.87      0.82       293\n",
      "         rap       0.72      0.50      0.59       311\n",
      "\n",
      "    accuracy                           0.69       900\n",
      "   macro avg       0.70      0.69      0.69       900\n",
      "weighted avg       0.70      0.69      0.68       900\n",
      "\n",
      "[[211  47  38]\n",
      " [121 155  35]\n",
      " [ 26  12 255]]\n"
     ]
    }
   ],
   "source": [
    "ypred = classifier.predict(Xtest)\n",
    "print(classification_report(ytest,ypred,target_names = ['pop','rock','rap']))\n",
    "print(confusion_matrix(ytest,ypred,labels = ['pop','rock','rap']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9a5ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pop       0.60      0.54      0.57       296\n",
      "        rock       0.87      0.78      0.83       293\n",
      "         rap       0.60      0.72      0.65       311\n",
      "\n",
      "    accuracy                           0.68       900\n",
      "   macro avg       0.69      0.68      0.68       900\n",
      "weighted avg       0.69      0.68      0.68       900\n",
      "\n",
      "[[159 113  24]\n",
      " [ 77 224  10]\n",
      " [ 27  36 230]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty=\"l2\", C=0.5, solver=\"liblinear\")\n",
    "lr.fit(Xtrain,ytrain)\n",
    "lrpred = lr.predict(Xtest)\n",
    "\n",
    "print(classification_report(ytest,lrpred,target_names = ['pop','rock','rap']))\n",
    "print(confusion_matrix(ytest,lrpred,labels = ['pop','rock','rap']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbb0b2",
   "metadata": {},
   "source": [
    "### 任务2: 接下来考虑加入音频特征，只使用朴素贝叶斯方法。流程如下：\n",
    "\n",
    "1. 接着上一问，使用训练集训练的朴素贝叶斯模型去在整个数据集做预测，得到三个种类的probability，将其中的两个（因为三者加和为1）作为两个新的特征和'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness','acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','duration_ms'这些音频特征中你觉得对预测有用的特征拼接在一起，作为新的特征（如果你觉得有必要的话，可以对特征进行进一步处理）；\n",
    "2. 使用新的特征，选择合适的朴素贝叶斯分类器，再次进行训练；\n",
    "3. 最后打印在测试集上的classification_report和confusion matrix；\n",
    "4. 你觉得这么操作有意义吗？请说明。\n",
    "\n",
    "提示：强烈建议直接调包，会很简单的。model.predict_proba(X)可以调出模型给出的分为各类的预测概率。关于最后一步，有时候理论正确的方法不一定有好的效果，有好的效果的方法不一定理论正确，看你自己的理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd15155d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pop       0.76      0.80      0.78       454\n",
      "        rock       0.89      0.85      0.87       461\n",
      "         rap       0.82      0.81      0.81       435\n",
      "\n",
      "    accuracy                           0.82      1350\n",
      "   macro avg       0.82      0.82      0.82      1350\n",
      "weighted avg       0.82      0.82      0.82      1350\n",
      "\n",
      "[[363  54  37]\n",
      " [ 71 352  12]\n",
      " [ 45  24 392]]\n"
     ]
    }
   ],
   "source": [
    "prob = classifier.predict_proba(X.A)\n",
    "#print(data.columns)\n",
    "#print(data.iloc[0])\n",
    "feature = [(prob[i][:2],data.iloc[i]['instrumentalness'],data.iloc[i]['mode'],data.iloc[i]['energy']) for i in range(0,len(prob))]\n",
    "#print(feature)\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(prob,data['playlist_genre'],test_size=0.3,random_state=1116)\n",
    "newclf = GaussianNB().fit(Xtrain,ytrain)\n",
    "ypred = newclf.predict(Xtest)\n",
    "print(classification_report(ytest,ypred,target_names = ['pop','rock','rap']))\n",
    "print(confusion_matrix(ytest,ypred,labels = ['pop','rock','rap']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c03d9d",
   "metadata": {},
   "source": [
    "有意义，理论上pop，rock和rap在人类可感知的特征上存在部分区别，把这些人为感知的特征与前面分类的得到的prob相结合，也许会提高准确度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c13550",
   "metadata": {},
   "source": [
    "### 附加题（2分）：\n",
    "\n",
    "你有没有其他能增大预测精确率和召回率的想法？叙述你的想法的原理和操作流程（1'），并简单用代码实现（1'）.设计时进行如下思考：\n",
    "1. （如果要使用深度学习模型）思考NLP任务中one-hot带来的维度灾难对深度学习模型训练带来的挑战，以及词向量化的解决方法\n",
    "2. 思考如何用恰当的方法，巧妙，优雅而有效地结合使用多种数据（在这个背景下就是文本数据和音频特征的结合使用）\n",
    "\n",
    "祝大家期中顺利～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
